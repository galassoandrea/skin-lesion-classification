{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09b0cda",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "To recap, in the EDA step, we found that:\n",
    "\n",
    "1. The dataset contains a total of 10015 images and all of them are referenced in the metadata file.\n",
    "2. There are a total of 7 diagnostic categories and the most common is \"melanocytic nevi\" (nv) suggesting that the dataset is highly imbalanced.\n",
    "3. There are some specific lesions represented by more than one image (same lesion_id, but different image_ids) with the maximum number of images per lesion equal to 6 and the average number equal to 1, evidencing that most lesions are represented by only one image.\n",
    "4. The categories in the images are, in general, distinguishable but, there are some cases in which images belonging to different diagnostic categories are very similar.\n",
    "5. In some images there are hairs covering the lesion.\n",
    "6. All the images in the dataset have the same dimension, which is more than 600x600.\n",
    "7. The pixel values are between 0 and 255.\n",
    "\n",
    "Given these information, this notebook aims to achieve 2 objectives:\n",
    "\n",
    "1. Resize all the images to a dimension suitable for model training.\n",
    "2. Split the dataset (both the metadata and the images) into training, validation and test sets.\n",
    "\n",
    "It could also be necessary to further preprocess the images containing hairs covering the lesion area but, since this would add an additional level of complexity, we will leave it for a later update and, for now, try to solve it through data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15705064",
   "metadata": {},
   "source": [
    "### Image resizing\n",
    "\n",
    "Let's start with the first point. For now, we want to resize the images to 224x224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73843df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images resized to 224x224 and saved to ..\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image as Image\n",
    "from pathlib import Path\n",
    "\n",
    "input_folders = [\n",
    "    Path(\"../data/raw/HAM10000_images_part_1\"),\n",
    "    Path(\"../data/raw/HAM10000_images_part_2\")\n",
    "]\n",
    "\n",
    "output_folder = Path(\"../data/processed\")\n",
    "\n",
    "for folder in input_folders:\n",
    "    for img_path in folder.glob(\"*.jpg\"):\n",
    "        img = Image.open(img_path)\n",
    "        img.resize((224,224), resample=Image.Resampling.LANCZOS)\n",
    "        img.save(output_folder / img_path.name)\n",
    "\n",
    "print(f\"All images resized to 224x224 and saved to {output_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f231da1",
   "metadata": {},
   "source": [
    "### Dataset Splitting\n",
    "\n",
    "At this point we need to split the dataset into training, validation and test set. In particular, based on the information obtained from the EDA step, we need to perform a stratified split in such a way that:\n",
    "\n",
    "1. All the images representing the same lesion (same lesion_id) are put inside the same subset.\n",
    "2. Each subset contains the same percentage of images belonging to each diagnostic category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "373477c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splitted into training, validation and test sets\n",
      "Train: 6981 images, Val: 1532, Test: 1502\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load metadata file\n",
    "input_dir = Path('../data/raw/HAM10000_metadata.csv')\n",
    "df = pd.read_csv(input_dir)\n",
    "\n",
    "# Get the lesions id and use them for the split\n",
    "lesions = df.groupby('lesion_id').first().reset_index()[['lesion_id', 'dx']]\n",
    "\n",
    "# Split lesions stratified by diagnosis (dx)\n",
    "train_lesions, temp_lesions = train_test_split(\n",
    "    lesions,\n",
    "    test_size=0.3,\n",
    "    stratify=lesions['dx'],\n",
    "    random_state=42\n",
    ")\n",
    "val_lesions, test_lesions = train_test_split(\n",
    "    temp_lesions,\n",
    "    test_size=0.5,\n",
    "    stratify=temp_lesions['dx'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Assign all images to their lesion's split\n",
    "train_df = df[df['lesion_id'].isin(train_lesions['lesion_id'])]\n",
    "val_df = df[df['lesion_id'].isin(val_lesions['lesion_id'])]\n",
    "test_df = df[df['lesion_id'].isin(test_lesions['lesion_id'])]\n",
    "\n",
    "# Save the splits\n",
    "columns_to_save = ['image_id', 'lesion_id', 'dx']\n",
    "train_df[columns_to_save].to_csv('../data/splits/train.csv', index=False)\n",
    "val_df[columns_to_save].to_csv('../data/splits/val.csv', index=False)\n",
    "test_df[columns_to_save].to_csv('../data/splits/test.csv', index=False)\n",
    "\n",
    "print(\"Dataset splitted into training, validation and test sets.\")\n",
    "print(f\"Train: {len(train_df)} images, Val: {len(val_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274e03e4",
   "metadata": {},
   "source": [
    "Finally, to deal with class imbalances, we want to compute class weights.\n",
    "In this way, we ensure that rare classes get higher weights while common classes (like \"nv\") get lower weights. This weights will be then used during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "853e555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {'bkl': np.float64(1.291820873427091), 'nv': np.float64(0.2129587260913334), 'df': np.float64(14.046277665995976), 'mel': np.float64(1.290149695065607), 'vasc': np.float64(10.073593073593074), 'bcc': np.float64(2.7625643055005935), 'akiec': np.float64(4.492277992277992)}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Compute class weights from training set\n",
    "classes = train_df['dx'].unique()\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=train_df['dx']\n",
    ")\n",
    "\n",
    "# Convert to dict for easy lookup\n",
    "class_weights_dict = {cls: weight for cls, weight in zip(classes, class_weights)}\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"../data/splits/class_weights.json\", \"w\") as f:\n",
    "    json.dump(class_weights_dict, f, indent=2)\n",
    "\n",
    "print(\"Class weights:\", class_weights_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
